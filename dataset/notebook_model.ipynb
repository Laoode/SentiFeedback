{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully and saved as dataset_translated.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL raw file GitHub\n",
    "url = \"https://raw.githubusercontent.com/Laoode/SentiFeedback/main/dataset/feedback%20student.csv\"\n",
    "\n",
    "# file_url = \"https://github.com/Laoode/SentiFeedback/blob/Agus_Workspace/dataset/dataset_translated.csv\"\n",
    "# file_url2 = \"https://github.com/Laoode/SentiFeedback/blob/main/dataset/feedback%20student.csv\"\n",
    "# Nama file untuk disimpan\n",
    "output_file = \"dataset_translated.csv\"\n",
    "\n",
    "# Unduh file\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"File downloaded successfully and saved as {output_file}\")\n",
    "else:\n",
    "    print(f\"Failed to download file. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: scikit-learn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: matplotlib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.8.2)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (1.67.1)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: rich in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m120.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m240.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m226.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m132.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.17.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, tensorflow-io-gcs-filesystem, safetensors, regex, optree, opt-einsum, ml-dtypes, h5py, google-pasta, gast, astunparse, tensorboard, huggingface-hub, tokenizers, seaborn, keras, transformers, tensorflow\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.15.1\n",
      "    Uninstalling tensorboard-2.15.1:\n",
      "      Successfully uninstalled tensorboard-2.15.1\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 h5py-3.12.1 huggingface-hub-0.26.2 keras-3.7.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 regex-2024.11.6 safetensors-0.4.5 seaborn-0.13.2 tensorboard-2.18.0 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 tokenizers-0.20.3 transformers-4.46.3 wrapt-1.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy tensorflow scikit-learn matplotlib seaborn transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (8.1.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipywidgets) (8.17.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: dejavu events execute kernel kernelspec lab\n",
      "labextension labhub migrate nbconvert run server troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n",
      "\u001b[33m(Deprecated) Installing extensions with the jupyter labextension install command is now deprecated and will be removed in a future major version of JupyterLab.\n",
      "\n",
      "Users should manage prebuilt extensions with package managers like pip and conda, and extension authors are encouraged to distribute their extensions as prebuilt packages \u001b[0m\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/jupyterlab/debuglog.py:54: UserWarning: An error occurred.\n",
      "  warnings.warn(\"An error occurred.\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/jupyterlab/debuglog.py:55: UserWarning: ValueError: Please install Node.js and npm before continuing installation. You may be able to install Node.js from your package manager, from conda, or directly from the Node.js website (https://nodejs.org).\n",
      "  warnings.warn(msg[-1].strip())\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/jupyterlab/debuglog.py:56: UserWarning: See the log file for details: /tmp/jupyterlab-debug-peyl_l1r.log\n",
      "  warnings.warn(f\"See the log file for details: {log_path!s}\")\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "!jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 16:11:27.837630: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-27 16:11:27.906685: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732723887.938963    4336 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732723887.947630    4336 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-27 16:11:28.017419: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>comment</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45881</td>\n",
       "      <td>Rand was a good guy, really... he was. But I f...</td>\n",
       "      <td>awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45881</td>\n",
       "      <td>He is brilliant in his field, but expects his ...</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45881</td>\n",
       "      <td>He has a major in philosophy which is why all ...</td>\n",
       "      <td>awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45881</td>\n",
       "      <td>I thought his class was extremely hard but des...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45881</td>\n",
       "      <td>I recently just finished taking Comp 110 with ...</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id                                            comment quality\n",
       "0  45881  Rand was a good guy, really... he was. But I f...   awful\n",
       "1  45881  He is brilliant in his field, but expects his ...    poor\n",
       "2  45881  He has a major in philosophy which is why all ...   awful\n",
       "3  45881  I thought his class was extremely hard but des...    good\n",
       "4  45881  I recently just finished taking Comp 110 with ...    poor"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('dataset_translated.csv', encoding='latin1')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['quality'] = df1['quality'].replace({\n",
    "    'awful': 0,\n",
    "    'poor': 1,\n",
    "    'average':2,\n",
    "    'good':3,\n",
    "    'awesome':4\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id      comment  quality\n",
      "40     45881  No Comments        0\n",
      "52     45881  No Comments        1\n",
      "58     45881  No Comments        1\n",
      "59     45881  No Comments        0\n",
      "159   601915  No Comments        1\n",
      "...      ...          ...      ...\n",
      "2324   64144  No Comments        3\n",
      "2336   64144  No Comments        3\n",
      "2341   64144  No Comments        3\n",
      "2343   64144  No Comments        0\n",
      "2344   64144  No Comments        0\n",
      "\n",
      "[75 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Memeriksa duplikat setelah perbaikan\n",
    "duplikat_baris = df1[df1.duplicated(subset=['Id', 'comment'], keep=False)]\n",
    "print(duplikat_baris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus baris yang memiliki komentar \"Tidak ada komentar\"\n",
    "df1 = df1[df1['comment'] != \"No Comments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus duplikat berdasarkan kombinasi Id dan Komentar\n",
    "df1 = df1.drop_duplicates(subset=['Id', 'comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Id, comment, quality]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Memeriksa duplikat setelah perbaikan\n",
    "duplikat_baris = df1[df1.duplicated(subset=['Id', 'comment'], keep=False)]\n",
    "print(duplikat_baris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(columns=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fc7bec510f4b7f8c22b165e3a5dc94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f76f457befc4c1db14ccc3647a2d724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e970215229402c8c5640b11d3d4575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fa08faf1374b9ca0f17ca312a628a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenizer.encode_plus(\n",
    "    df1['comment'].iloc[0],\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    add_special_tokens=True,\n",
    "    return_tensors='tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 256), dtype=int32, numpy=\n",
       "array([[  101, 16731,  1108,   170,  1363,  2564,   117,  1541,   119,\n",
       "          119,   119,  1119,  1108,   119,  1252,   146,  1464,  1119,\n",
       "         1125,  1126, 13000,   118, 15550,  1165,  1119,  1286,  1106,\n",
       "         1301,  1313,  1105,  3654,   119,  1230, 11471,  1105,  1293,\n",
       "         1119,  3015,  3966,  1117,  1651,  4580,  1108,  2566,  1136,\n",
       "         4652,   119,  5630,   117,  1632,  2564,  1133,  3644,  1142,\n",
       "         1705,  1114,  1140,   106,   106,   106,   102,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input_ids = np.zeros((len(df1), 256))\n",
    "X_attn_masks = np.zeros((len(df1), 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(df, ids, masks, tokenizer):\n",
    "    for i, text in tqdm(enumerate(df1['comment'])):\n",
    "        tokenized_text = tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=256,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        ids[i, :] = tokenized_text.input_ids\n",
    "        masks[i, :] = tokenized_text.attention_mask\n",
    "    return ids, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter\n",
      "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: jupyterlab in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.2.0)\n",
      "Collecting jupyterlab\n",
      "  Downloading jupyterlab-4.3.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: ipywidgets in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (8.1.1)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting notebook (from jupyter)\n",
      "  Downloading notebook-7.2.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jupyter-console (from jupyter)\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: nbconvert in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter) (7.16.4)\n",
      "Requirement already satisfied: ipykernel in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter) (6.26.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab) (0.27.2)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab) (2.14.2)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab) (24.1)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab) (75.1.0)\n",
      "Requirement already satisfied: tomli>=1.2.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab) (2.0.2)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab) (6.4.1)\n",
      "Requirement already satisfied: traitlets in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipywidgets) (8.17.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from async-lru>=1.0.0->jupyterlab) (4.12.2)\n",
      "Requirement already satisfied: anyio in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab) (1.0.6)\n",
      "Requirement already satisfied: idna in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab) (3.10)\n",
      "Requirement already satisfied: sniffio in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.14.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipykernel->jupyter) (1.8.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipykernel->jupyter) (6.1.0)\n",
      "Requirement already satisfied: pyzmq>=20 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipykernel->jupyter) (26.2.0)\n",
      "Requirement already satisfied: decorator in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2>=3.0.3->jupyterlab) (3.0.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter-core->jupyterlab) (4.3.6)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.21.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.16.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.9.25)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nbconvert->jupyter) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nbconvert->jupyter) (0.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nbconvert->jupyter) (1.4.0)\n",
      "Collecting jupyterlab\n",
      "  Downloading jupyterlab-4.2.6-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: webencodings in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.20.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.2.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: fqdn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.8.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.20241003)\n",
      "Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading notebook-7.2.2-py3-none-any.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m148.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab-4.2.6-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m246.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ipywidgets, jupyter-console, jupyterlab, notebook, jupyter\n",
      "  Attempting uninstall: ipywidgets\n",
      "    Found existing installation: ipywidgets 8.1.1\n",
      "    Uninstalling ipywidgets-8.1.1:\n",
      "      Successfully uninstalled ipywidgets-8.1.1\n",
      "  Attempting uninstall: jupyterlab\n",
      "    Found existing installation: jupyterlab 4.2.0\n",
      "    Uninstalling jupyterlab-4.2.0:\n",
      "      Successfully uninstalled jupyterlab-4.2.0\n",
      "Successfully installed ipywidgets-8.1.5 jupyter-1.1.1 jupyter-console-6.6.3 jupyterlab-4.2.6 notebook-7.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade jupyter jupyterlab ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec94e31f11684a1e857ed1ae37d2d493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_input_ids, X_attn_masks = generate_training_data(df1, X_input_ids, X_attn_masks, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2273, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.zeros((len(df1), 5))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "4    611\n",
       "0    472\n",
       "3    431\n",
       "1    383\n",
       "2    376\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[np.arange(len(df1)), df1['quality'].values] = 1 # one-hot encoded target tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(256,), dtype=tf.float64, name=None), TensorSpec(shape=(256,), dtype=tf.float64, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a data pipeline using tensorflow dataset utility, creates batches of data for easy loading...\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels))\n",
    "dataset.take(1) # one sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentimentDatasetMapFunction(input_ids, attn_masks, labels):\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attn_masks\n",
    "    }, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(SentimentDatasetMapFunction) # converting to required format for tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(256,), dtype=tf.float64, name=None), 'attention_mask': TensorSpec(shape=(256,), dtype=tf.float64, name=None)}, TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(10000).batch(16, drop_remainder=True) # batch size, drop any left out tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 256), dtype=tf.float64, name=None), 'attention_mask': TensorSpec(shape=(16, 256), dtype=tf.float64, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.8\n",
    "train_size = int((len(df1)//16)*p) # for each 16 batch of data we will have len(df)//16 samples, take 80% of that for train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.23.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2f7ee7bdad4a6299eb1bd034d3a4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertModel.from_pretrained('bert-base-cased') # bert base model with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 256)]                0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 256)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)      TFBaseModelOutputWithPooli   1083102   ['input_ids[0][0]',           \n",
      "                             ngAndCrossAttentions(last_   72         'attention_mask[0][0]']      \n",
      "                             hidden_state=(None, 256, 7                                           \n",
      "                             68),                                                                 \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " intermediate_layer (Dense)  (None, 512)                  393728    ['bert[0][1]']                \n",
      "                                                                                                  \n",
      " output_layer (Dense)        (None, 5)                    2565      ['intermediate_layer[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108706565 (414.68 MB)\n",
      "Trainable params: 108706565 (414.68 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining 2 input layers for input_ids and attn_masks\n",
    "input_ids = tf.keras.layers.Input(shape=(256,), name='input_ids', dtype='int32')\n",
    "attn_masks = tf.keras.layers.Input(shape=(256,), name='attention_mask', dtype='int32')\n",
    "\n",
    "bert_embds = model.bert(input_ids, attention_mask=attn_masks)[1] # 0 -> activation layer (3D), 1 -> pooled output layer (2D)\n",
    "intermediate_layer = tf.keras.layers.Dense(512, activation='relu', name='intermediate_layer')(bert_embds)\n",
    "output_layer = tf.keras.layers.Dense(5, activation='softmax', name='output_layer')(intermediate_layer) # softmax -> calcs probs of classes\n",
    "\n",
    "sentiment_model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)\n",
    "sentiment_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define learning rate decay using ExponentialDecay\n",
    "learning_rate_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-5,\n",
    "    decay_steps=100000,  # Number of steps before the learning rate is decayed\n",
    "    decay_rate=0.96,  # The rate at which the learning rate decays\n",
    "    staircase=True  # If True, the learning rate is decayed at discrete intervals\n",
    ")\n",
    "\n",
    "# Adam optimizer with learning rate schedule\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=learning_rate_schedule)\n",
    "\n",
    "# Loss function and metrics\n",
    "loss_func = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model.compile(optimizer=optim, loss=loss_func, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "113/113 [==============================] - 1194s 10s/step - loss: 1.3960 - accuracy: 0.3833 - val_loss: 1.1115 - val_accuracy: 0.4677\n",
      "Epoch 2/5\n",
      "113/113 [==============================] - 1128s 10s/step - loss: 1.0921 - accuracy: 0.5216 - val_loss: 0.9191 - val_accuracy: 0.6078\n",
      "Epoch 3/5\n",
      "113/113 [==============================] - 1239s 11s/step - loss: 0.9686 - accuracy: 0.5929 - val_loss: 0.8414 - val_accuracy: 0.6573\n",
      "Epoch 4/5\n",
      "113/113 [==============================] - 1162s 10s/step - loss: 0.8592 - accuracy: 0.6322 - val_loss: 0.6362 - val_accuracy: 0.7716\n",
      "Epoch 5/5\n",
      "113/113 [==============================] - 1173s 10s/step - loss: 0.7226 - accuracy: 0.7030 - val_loss: 0.5544 - val_accuracy: 0.8103\n"
     ]
    }
   ],
   "source": [
    "hist = sentiment_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan model\n",
    "sentiment_model.save(\"saved_models/bert_sentiment_model\")\n",
    "\n",
    "# Muat kembali model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model = load_model(\"saved_models/bert_sentiment_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Simpan model dalam format .h5\n",
    "sentiment_model.save(\"model_h5/bert_sentiment_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model.save(\"model_keras/bert_sentiment_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpw07z70pt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpw07z70pt/assets\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1732710601.265421   14783 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732710601.267891   14783 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2024-11-27 12:30:01.286863: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpw07z70pt\n",
      "2024-11-27 12:30:01.337870: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-11-27 12:30:01.338003: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpw07z70pt\n",
      "I0000 00:00:1732710601.520514   14783 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
      "2024-11-27 12:30:01.540638: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-11-27 12:30:05.475094: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpw07z70pt\n",
      "2024-11-27 12:30:05.734275: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 4447499 microseconds.\n",
      "2024-11-27 12:30:06.266095: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model TFLite disimpan di: saved_models-tflite/bert_sentiment_model.tflite\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Path untuk menyimpan model TFLite\n",
    "tflite_model_path = \"saved_models-tflite/bert_sentiment_model.tflite\"\n",
    "\n",
    "# Konversi model ke TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(sentiment_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Simpan model TFLite\n",
    "with open(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"Model TFLite disimpan di: {tflite_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "113/113 [==============================] - 1198s 11s/step - loss: 0.6472 - accuracy: 0.7439 - val_loss: 0.4471 - val_accuracy: 0.8578\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 1186s 10s/step - loss: 0.5349 - accuracy: 0.7876 - val_loss: 0.4337 - val_accuracy: 0.8470\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 1247s 11s/step - loss: 0.4643 - accuracy: 0.8291 - val_loss: 0.2750 - val_accuracy: 0.9289\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 1209s 11s/step - loss: 0.3612 - accuracy: 0.8805 - val_loss: 0.2313 - val_accuracy: 0.9353\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 1195s 11s/step - loss: 0.2832 - accuracy: 0.9060 - val_loss: 0.1939 - val_accuracy: 0.9246\n"
     ]
    }
   ],
   "source": [
    "# Melanjutkan training model\n",
    "hist_continue = sentiment_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10,  # Tambahkan epoch tambahan\n",
    "    initial_epoch=5  # Mulai dari epoch terakhir (epoch sebelumnya adalah 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_aft10_epoch/bert_sentiment_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_aft10_epoch/bert_sentiment_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Simpan model\n",
    "sentiment_model.save(\"model_aft10_epoch/bert_sentiment_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 83s 3s/step - loss: 0.2415 - accuracy: 0.9267\n",
      "Validation Loss: 0.24148298799991608\n",
      "Validation Accuracy: 0.9267241358757019\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi pada validation dataset\n",
    "loss, accuracy = sentiment_model.evaluate(val_dataset)\n",
    "print(f\"Validation Loss: {loss}\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model extracted to: models\n"
     ]
    }
   ],
   "source": [
    "# Nama file ZIP\n",
    "zip_file = \"model_aft10_epoch.zip\"\n",
    "\n",
    "# Folder tujuan untuk ekstraksi\n",
    "output_folder = \"models\"\n",
    "\n",
    "# Ekstrak file ZIP\n",
    "with ZipFile(zip_file, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(output_folder)\n",
    "print(f\"Model extracted to: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf_keras\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tf_keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (4.23.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf_keras) (0.44.0)\n",
      "Requirement already satisfied: rich in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (13.9.4)\n",
      "Requirement already satisfied: namex in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.1.2)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tf_keras\n",
      "Successfully installed tf_keras-2.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "import tf_keras as k3\n",
    "\n",
    "sentiment_model = k3.models.load_model('models/bert_sentiment_model')\n",
    "\n",
    "print(\"Model successfully loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1226s 11s/step - loss: 0.2505 - accuracy: 0.9126 - val_loss: 0.1972 - val_accuracy: 0.9332\n",
      "Epoch 12/15\n",
      "113/113 [==============================] - 1212s 11s/step - loss: 0.1872 - accuracy: 0.9441 - val_loss: 0.1106 - val_accuracy: 0.9634\n",
      "Epoch 13/15\n",
      "113/113 [==============================] - 1218s 11s/step - loss: 0.1561 - accuracy: 0.9546 - val_loss: 0.0645 - val_accuracy: 0.9828\n",
      "Epoch 14/15\n",
      "113/113 [==============================] - 1198s 11s/step - loss: 0.1356 - accuracy: 0.9580 - val_loss: 0.0713 - val_accuracy: 0.9806\n",
      "Epoch 15/15\n",
      "113/113 [==============================] - 1205s 11s/step - loss: 0.1097 - accuracy: 0.9674 - val_loss: 0.0494 - val_accuracy: 0.9806\n"
     ]
    }
   ],
   "source": [
    "# Latihan ulang dengan 5 epoch tambahan tanpa EarlyStopping\n",
    "history = sentiment_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=15,  # Total 15 epoch, melanjutkan dari epoch 10\n",
    "    initial_epoch=10  # Mulai dari epoch terakhir (epoch 10 sebelumnya)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_aft15_epoch/bert_sentiment_model_finetuned/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_aft15_epoch/bert_sentiment_model_finetuned/assets\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f80151e1480> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f80151e1450> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f801517f100> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f801517e4a0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f801517e050> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f801517c880> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f801515bb80> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f801515b490> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f8015159c60> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f8015158e80> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f8015158790> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f8015337250> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f80153365c0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f8015335d80> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f8015334430> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f80153133d0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f8015312b90> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f80153112a0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f8015310280> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f80152f3a30> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f80152f2170> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f80152f1090> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f80152f0790> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f80152daef0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f80152d9ea0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f80152d9660> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f80152abd30> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f80152aace0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f80152aa4a0> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f80152a9fc0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f373a5b40> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f7f373a6920> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f373eada0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36992620> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f7f3711be80> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f37147640> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f371693c0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f7f3716a080> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f3718d240> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f3718ded0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f3718fc70> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f371b1cc0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f7f371b3bb0> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f371d5c30> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f371d7640> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f371fc880> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f371fe3b0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f7f371ffca0> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f3707df30> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f3707f2e0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36f34730> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36f36a40> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f7f36fb4250> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36fb66e0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36fb7640> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36e64dc0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36e670d0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f7f3731fa00> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f3731d570> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f3731eef0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f3731d540> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f37362f50> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f7f373613c0> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f37362c20> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f37361120> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f373613f0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36d11d50> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f7f36d12f80> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36ca5840> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36ca7520> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36bc1810> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36aaf220> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f7f36aaf850> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36aaeaa0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36af44c0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36af4ac0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f3699fd60> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f801539e0b0> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f80152291e0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f8015228ac0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f8015228190> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f367f8370> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f7f3664d150> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f367ec610> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f367ef490> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f367ede10> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f367ef790> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f7f367eeec0> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f367eec20> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f367efac0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f367ef8e0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36671c90> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f7f36673550> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36670220> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36672320> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f366733d0> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.Dense object at 0x7f7f36670100> has the same name 'Dense' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf_keras.src.saving.legacy.saved_model.load.LayerNormalization object at 0x7f7f366702b0> has the same name 'LayerNormalization' as a built-in TF-Keras object. Consider renaming <class 'tf_keras.src.saving.legacy.saved_model.load.LayerNormalization'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved after additional epochs.\n"
     ]
    }
   ],
   "source": [
    "# Simpan model setelah fine-tuning\n",
    "sentiment_model.save(\"model_aft15_epoch/bert_sentiment_model_finetuned\")\n",
    "print(\"Model saved after additional epochs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 82s 3s/step - loss: 0.0571 - accuracy: 0.9871\n",
      "Validation Loss: 0.057098984718322754\n",
      "Validation Accuracy: 0.9870689511299133\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi pada validation dataset\n",
    "loss, accuracy = sentiment_model.evaluate(val_dataset)\n",
    "print(f\"Validation Loss: {loss}\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model = k3.models.load_model('model_aft15_epoch/bert_sentiment_model_finetuned')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "def prepare_data(input_text, tokenizer):\n",
    "    token = tokenizer.encode_plus(\n",
    "        input_text,\n",
    "        max_length=256, \n",
    "        truncation=True, \n",
    "        padding='max_length', \n",
    "        add_special_tokens=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    return {\n",
    "        'input_ids': tf.cast(token.input_ids, tf.float64),\n",
    "        'attention_mask': tf.cast(token.attention_mask, tf.float64)\n",
    "    }\n",
    "\n",
    "def make_prediction(model, processed_data, classes=['Awful', 'Poor', 'Neutral', 'Good', 'Awesome']):\n",
    "    probs = model.predict(processed_data)[0]\n",
    "    return classes[np.argmax(probs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted Sentiment: Good\n"
     ]
    }
   ],
   "source": [
    "input_text = input('Enter your feedback here: ')\n",
    "processed_data = prepare_data(input_text, tokenizer)\n",
    "result = make_prediction(sentiment_model, processed_data=processed_data)\n",
    "print(f\"Predicted Sentiment: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 364ms/step\n",
      "Predicted Sentiment: Awful\n"
     ]
    }
   ],
   "source": [
    "input_text = 'A lot of speaking without any sense. Skip it at all cost'\n",
    "processed_data = prepare_data(input_text, tokenizer)\n",
    "result = make_prediction(sentiment_model, processed_data=processed_data)\n",
    "print(f\"Predicted Sentiment: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 270ms/step\n",
      "Predicted Sentiment: Poor\n"
     ]
    }
   ],
   "source": [
    "input_text = 'Course was not easy to grasp, lost interest after the first week and I barely got through the quiz at the end.'\n",
    "processed_data = prepare_data(input_text, tokenizer)\n",
    "result = make_prediction(sentiment_model, processed_data=processed_data)\n",
    "print(f\"Predicted Sentiment: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 285ms/step\n",
      "Predicted Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "input_text = \"The first three weeks focussed heavily on ratios and detecting fraud and earnings management in an organization, the fourth week seemed to actually relate to data analytics and how non-financial aspects of a company play a role in the financial outcomes. I really do not see where a data analyst who is not in accounting field would be using the fraud detection scenarios in real life. A data analyst would be focused on improving the business and doing the analyses that pertain to improving certain aspects of a business, not finding his manager's earnings management using an M-score etc.\"\n",
    "processed_data = prepare_data(input_text, tokenizer)\n",
    "result = make_prediction(sentiment_model, processed_data=processed_data)\n",
    "print(f\"Predicted Sentiment: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 242ms/step\n",
      "Predicted Sentiment: Awesome\n"
     ]
    }
   ],
   "source": [
    "input_text = \"It was very well done and very informational. Thanks again professors for your dedication and time to educate society!\"\n",
    "processed_data = prepare_data(input_text, tokenizer)\n",
    "result = make_prediction(sentiment_model, processed_data=processed_data)\n",
    "print(f\"Predicted Sentiment: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kode Konversi ke TF Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1732733141.192025    4336 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732733141.194027    4336 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2024-11-27 18:45:41.198420: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: model_aft15_epoch/bert_sentiment_model_finetuned\n",
      "2024-11-27 18:45:41.245792: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-11-27 18:45:41.245838: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: model_aft15_epoch/bert_sentiment_model_finetuned\n",
      "I0000 00:00:1732733141.390394    4336 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
      "2024-11-27 18:45:41.409587: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-11-27 18:45:44.133647: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: model_aft15_epoch/bert_sentiment_model_finetuned\n",
      "2024-11-27 18:45:44.406259: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 3207925 microseconds.\n",
      "2024-11-27 18:45:44.674037: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model successfully saved to: tf_lite/bert_sentiment_model.tflite\n"
     ]
    }
   ],
   "source": [
    "# Path untuk menyimpan model TFLite\n",
    "tflite_model_path = \"tf_lite/bert_sentiment_model.tflite\"\n",
    "\n",
    "# Konversi model ke format TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"model_aft15_epoch/bert_sentiment_model_finetuned\")  # Path ke model disimpan\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Simpan model TFLite ke file\n",
    "with open(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model successfully saved to: {tflite_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kode Konversi ke HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully saved to: HDF5/bert_sentiment_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Path untuk menyimpan model dalam format HDF5\n",
    "h5_model_path = \"HDF5/bert_sentiment_model.h5\"\n",
    "\n",
    "# Simpan model ke format HDF5\n",
    "sentiment_model.save(h5_model_path, save_format='h5')\n",
    "\n",
    "print(f\"Model successfully saved to: {h5_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daftar modul manual telah disimpan ke 'requirements.txt'\n"
     ]
    }
   ],
   "source": [
    "# Daftar modul dan versi\n",
    "used_modules = {\n",
    "    \"tf_keras\": \"2.18.0\",  \n",
    "    \"tensorflow\": tf.__version__,\n",
    "    \"transformers\": transformers.__version__,\n",
    "    \"pandas\": pd.__version__,\n",
    "    \"numpy\": np.__version__,\n",
    "    \"tqdm\": \"4.66.6\",\n",
    "    \"scikit-learn\": sklearn.__version__,\n",
    "    \"matplotlib\": matplotlib.__version__,\n",
    "    \"seaborn\": seaborn.__version__\n",
    "}\n",
    "\n",
    "# Simpan ke file\n",
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    for name, version in used_modules.items():\n",
    "        f.write(f\"{name}=={version}\\n\")\n",
    "\n",
    "print(\"Daftar modul manual telah disimpan ke 'requirements.txt'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
