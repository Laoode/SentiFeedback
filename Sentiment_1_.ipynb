{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIkAMlbIKngGlDg4dwAPnq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laoode/SentiFeedback/blob/Salma_Workspace/Sentiment_1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Preprocessing"
      ],
      "metadata": {
        "id": "Hqd9pU6PeSaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = '/content/feedback student (3).csv'\n",
        "\n",
        "# Coba dengan encoding 'utf-8'\n",
        "try:\n",
        "    df = pd.read_csv(path, encoding='utf-8')\n",
        "    print(df.head())\n",
        "except UnicodeDecodeError:\n",
        "    # Jika terjadi error, coba dengan encoding lain seperti 'ISO-8859-1'\n",
        "    df = pd.read_csv(path, encoding='ISO-8859-1')\n",
        "    print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqgUzxqkeV2B",
        "outputId": "b698cc74-dc63-4ceb-df3d-1a72297e1856"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Id                                            comment quality\n",
            "0  45881  Rand was a good guy, really... he was. But I f...   awful\n",
            "1  45881  He is brilliant in his field, but expects his ...    poor\n",
            "2  45881  He has a major in philosophy which is why all ...   awful\n",
            "3  45881  I thought his class was extremely hard but des...    good\n",
            "4  45881  I recently just finished taking Comp 110 with ...    poor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_n04xsOe6Y8",
        "outputId": "7bc02076-17bb-40dd-98e9-f01cd02baf60"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2345 entries, 0 to 2344\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Id       2345 non-null   int64 \n",
            " 1   comment  2345 non-null   object\n",
            " 2   quality  2345 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 55.1+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDeskripsi statistik:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24AMpVr9feYs",
        "outputId": "85c4b0de-c2db-41c8-a046-10e5af6d6789"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Deskripsi statistik:\n",
            "                 Id\n",
            "count  2.345000e+03\n",
            "mean   3.216152e+05\n",
            "std    3.322920e+05\n",
            "min    4.588100e+04\n",
            "25%    1.091930e+05\n",
            "50%    1.580880e+05\n",
            "75%    3.196410e+05\n",
            "max    1.307460e+06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cPTY_jXfjQo",
        "outputId": "6d9abfd2-2bc4-43cd-c397-7bf98f532f73"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2345, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8KDj3N8fzHa",
        "outputId": "cfa51858-5051-44e1-9f8f-669b24c71f48"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Id         0\n",
            "comment    0\n",
            "quality    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values_summary = df.isnull().sum()\n",
        "print(\"Ringkasan nilai yang hilang:\")\n",
        "print(missing_values_summary)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hySAAn0NhPGe",
        "outputId": "67b59762-153c-4bb1-bc6f-872c33cc9018"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ringkasan nilai yang hilang:\n",
            "Id         0\n",
            "comment    0\n",
            "quality    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cek apakah kolom 'Rating' ada dalam dataset\n",
        "if 'quality' in df.columns:\n",
        "    # Melihat nilai unik dan jumlah kemunculannya pada kolom 'Rating'\n",
        "    rating_counts = df['quality'].value_counts()\n",
        "    print(\"\\nNilai unik pada kolom 'Rating' dan jumlah kemunculannya:\")\n",
        "    print(rating_counts)\n",
        "else:\n",
        "    print(\"\\nKolom 'quality' tidak ditemukan dalam dataset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n17KhKiBwMCM",
        "outputId": "b16aa472-3e33-41f8-e53e-3acb6063856f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nilai unik pada kolom 'Rating' dan jumlah kemunculannya:\n",
            "quality\n",
            "Awesome    629\n",
            "Awful      489\n",
            "Good       449\n",
            "Poor       397\n",
            "Average    381\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat peta untuk mengelompokkan kualitas menjadi Good dan Bad\n",
        "quality_mapping = {\n",
        "    'Awesome': 'Good',\n",
        "    'Good': 'Good',\n",
        "    'Average': 'Good',\n",
        "    'Awful': 'Bad',\n",
        "    'Poor': 'Bad'\n",
        "}\n",
        "\n",
        "# Menambahkan kolom baru dengan kategori yang telah dikelompokkan\n",
        "df['quality_grouped'] = df['quality'].map(quality_mapping)\n",
        "\n",
        "# Menampilkan hasil setelah pengelompokan\n",
        "print(\"Data Setelah Pengelompokan Kualitas:\")\n",
        "print(df[['quality', 'quality_grouped']].head())\n",
        "\n",
        "# Melihat nilai unik dan jumlah kemunculan kategori Good dan Bad\n",
        "quality_grouped_counts = df['quality_grouped'].value_counts()\n",
        "print(\"\\nJumlah Kategori Good dan Bad:\")\n",
        "print(quality_grouped_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Irs1Pi_SxCUJ",
        "outputId": "f129746b-a806-4232-aad2-54ddf121adcb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Setelah Pengelompokan Kualitas:\n",
            "  quality quality_grouped\n",
            "0   Awful             Bad\n",
            "1    Poor             Bad\n",
            "2   Awful             Bad\n",
            "3    Good            Good\n",
            "4    Poor             Bad\n",
            "\n",
            "Jumlah Kategori Good dan Bad:\n",
            "quality_grouped\n",
            "Good    1459\n",
            "Bad      886\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Case Folding (mengubah teks menjadi huruf kecil)\n",
        "df['comment_clean'] = df['comment'].str.lower()\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"Data setelah case folding:\")\n",
        "print(df[['comment', 'comment_clean']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRnYLs9_i3ot",
        "outputId": "f9556a45-df6c-4489-df9a-d8b4671f2bca"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data setelah case folding:\n",
            "                                                comment  \\\n",
            "0     Rand was a good guy, really... he was. But I f...   \n",
            "1     He is brilliant in his field, but expects his ...   \n",
            "2     He has a major in philosophy which is why all ...   \n",
            "3     I thought his class was extremely hard but des...   \n",
            "4     I recently just finished taking Comp 110 with ...   \n",
            "...                                                 ...   \n",
            "2340  He's really disoriented, but a really cool guy...   \n",
            "2341                                        No Comments   \n",
            "2342                                           Horrible   \n",
            "2343                                        No Comments   \n",
            "2344                                        No Comments   \n",
            "\n",
            "                                          comment_clean  \n",
            "0     rand was a good guy, really... he was. but i f...  \n",
            "1     he is brilliant in his field, but expects his ...  \n",
            "2     he has a major in philosophy which is why all ...  \n",
            "3     i thought his class was extremely hard but des...  \n",
            "4     i recently just finished taking comp 110 with ...  \n",
            "...                                                 ...  \n",
            "2340  he's really disoriented, but a really cool guy...  \n",
            "2341                                        no comments  \n",
            "2342                                           horrible  \n",
            "2343                                        no comments  \n",
            "2344                                        no comments  \n",
            "\n",
            "[2345 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "# Unduh resource 'punkt' untuk tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Tokenization: Memecah teks menjadi kata-kata menggunakan word_tokenize\n",
        "df['comment_tokenized'] = df['comment_clean'].apply(word_tokenize)\n",
        "\n",
        "# Menampilkan hasil setelah Filtering dan Tokenization\n",
        "print(\"Data setelah Filtering dan Tokenization:\")\n",
        "print(df[['comment', 'comment_clean', 'comment_tokenized']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtyIeSRsjcsT",
        "outputId": "423b3b8f-aabf-49ed-f754-28cb574dd0b6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data setelah Filtering dan Tokenization:\n",
            "                                                comment  \\\n",
            "0     Rand was a good guy, really... he was. But I f...   \n",
            "1     He is brilliant in his field, but expects his ...   \n",
            "2     He has a major in philosophy which is why all ...   \n",
            "3     I thought his class was extremely hard but des...   \n",
            "4     I recently just finished taking Comp 110 with ...   \n",
            "...                                                 ...   \n",
            "2340  He's really disoriented, but a really cool guy...   \n",
            "2341                                        No Comments   \n",
            "2342                                           Horrible   \n",
            "2343                                        No Comments   \n",
            "2344                                        No Comments   \n",
            "\n",
            "                                          comment_clean  \\\n",
            "0     rand was a good guy really he was but i felt h...   \n",
            "1     he is brilliant in his field but expects his s...   \n",
            "2     he has a major in philosophy which is why all ...   \n",
            "3     i thought his class was extremely hard but des...   \n",
            "4     i recently just finished taking comp  with ran...   \n",
            "...                                                 ...   \n",
            "2340  hes really disoriented but a really cool guy a...   \n",
            "2341                                        no comments   \n",
            "2342                                           horrible   \n",
            "2343                                        no comments   \n",
            "2344                                        no comments   \n",
            "\n",
            "                                      comment_tokenized  \n",
            "0     [rand, was, a, good, guy, really, he, was, but...  \n",
            "1     [he, is, brilliant, in, his, field, but, expec...  \n",
            "2     [he, has, a, major, in, philosophy, which, is,...  \n",
            "3     [i, thought, his, class, was, extremely, hard,...  \n",
            "4     [i, recently, just, finished, taking, comp, wi...  \n",
            "...                                                 ...  \n",
            "2340  [hes, really, disoriented, but, a, really, coo...  \n",
            "2341                                     [no, comments]  \n",
            "2342                                         [horrible]  \n",
            "2343                                     [no, comments]  \n",
            "2344                                     [no, comments]  \n",
            "\n",
            "[2345 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "# Unduh resource yang diperlukan\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# Stopword Removal: Menghapus kata umum yang tidak penting\n",
        "# Menggunakan stopwords bahasa Inggris\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Menghapus stopwords dari tokenized words\n",
        "df['comment_tokenized_cleaned'] = df['comment_tokenized'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "\n",
        "# Menampilkan hasil setelah Stopword Removal\n",
        "print(\"Data setelah Stopword Removal:\")\n",
        "print(df[['comment', 'comment_clean', 'comment_tokenized', 'comment_tokenized_cleaned']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46LV8MU6ncQt",
        "outputId": "97dace8a-06bb-414a-da78-9f83396be324"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data setelah Stopword Removal:\n",
            "                                                comment  \\\n",
            "0     Rand was a good guy, really... he was. But I f...   \n",
            "1     He is brilliant in his field, but expects his ...   \n",
            "2     He has a major in philosophy which is why all ...   \n",
            "3     I thought his class was extremely hard but des...   \n",
            "4     I recently just finished taking Comp 110 with ...   \n",
            "...                                                 ...   \n",
            "2340  He's really disoriented, but a really cool guy...   \n",
            "2341                                        No Comments   \n",
            "2342                                           Horrible   \n",
            "2343                                        No Comments   \n",
            "2344                                        No Comments   \n",
            "\n",
            "                                          comment_clean  \\\n",
            "0     rand was a good guy really he was but i felt h...   \n",
            "1     he is brilliant in his field but expects his s...   \n",
            "2     he has a major in philosophy which is why all ...   \n",
            "3     i thought his class was extremely hard but des...   \n",
            "4     i recently just finished taking comp  with ran...   \n",
            "...                                                 ...   \n",
            "2340  hes really disoriented but a really cool guy a...   \n",
            "2341                                        no comments   \n",
            "2342                                           horrible   \n",
            "2343                                        no comments   \n",
            "2344                                        no comments   \n",
            "\n",
            "                                      comment_tokenized  \\\n",
            "0     [rand, was, a, good, guy, really, he, was, but...   \n",
            "1     [he, is, brilliant, in, his, field, but, expec...   \n",
            "2     [he, has, a, major, in, philosophy, which, is,...   \n",
            "3     [i, thought, his, class, was, extremely, hard,...   \n",
            "4     [i, recently, just, finished, taking, comp, wi...   \n",
            "...                                                 ...   \n",
            "2340  [hes, really, disoriented, but, a, really, coo...   \n",
            "2341                                     [no, comments]   \n",
            "2342                                         [horrible]   \n",
            "2343                                     [no, comments]   \n",
            "2344                                     [no, comments]   \n",
            "\n",
            "                              comment_tokenized_cleaned  \n",
            "0     [rand, good, guy, really, felt, alterego, left...  \n",
            "1     [brilliant, field, expects, students, perform,...  \n",
            "2     [major, philosophy, papers, write, based, phil...  \n",
            "3     [thought, class, extremely, hard, despite, bec...  \n",
            "4     [recently, finished, taking, comp, rand, harde...  \n",
            "...                                                 ...  \n",
            "2340  [hes, really, disoriented, really, cool, guy, ...  \n",
            "2341                                         [comments]  \n",
            "2342                                         [horrible]  \n",
            "2343                                         [comments]  \n",
            "2344                                         [comments]  \n",
            "\n",
            "[2345 rows x 4 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Unduh resource yang diperlukan\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# Stemming: Mengubah kata ke bentuk dasar menggunakan PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "df['comment_tokenized_stemmed'] = df['comment_tokenized_cleaned'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
        "\n",
        "# Menampilkan hasil setelah Stemming\n",
        "print(\"Data setelah Stemming:\")\n",
        "print(df[['comment', 'comment_clean', 'comment_tokenized', 'comment_tokenized_cleaned', 'comment_tokenized_stemmed']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxOLswqio9Li",
        "outputId": "271ad675-1f70-43d6-fe38-b31ac6e69a58"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data setelah Stemming:\n",
            "                                                comment  \\\n",
            "0     Rand was a good guy, really... he was. But I f...   \n",
            "1     He is brilliant in his field, but expects his ...   \n",
            "2     He has a major in philosophy which is why all ...   \n",
            "3     I thought his class was extremely hard but des...   \n",
            "4     I recently just finished taking Comp 110 with ...   \n",
            "...                                                 ...   \n",
            "2340  He's really disoriented, but a really cool guy...   \n",
            "2341                                        No Comments   \n",
            "2342                                           Horrible   \n",
            "2343                                        No Comments   \n",
            "2344                                        No Comments   \n",
            "\n",
            "                                          comment_clean  \\\n",
            "0     rand was a good guy really he was but i felt h...   \n",
            "1     he is brilliant in his field but expects his s...   \n",
            "2     he has a major in philosophy which is why all ...   \n",
            "3     i thought his class was extremely hard but des...   \n",
            "4     i recently just finished taking comp  with ran...   \n",
            "...                                                 ...   \n",
            "2340  hes really disoriented but a really cool guy a...   \n",
            "2341                                        no comments   \n",
            "2342                                           horrible   \n",
            "2343                                        no comments   \n",
            "2344                                        no comments   \n",
            "\n",
            "                                      comment_tokenized  \\\n",
            "0     [rand, was, a, good, guy, really, he, was, but...   \n",
            "1     [he, is, brilliant, in, his, field, but, expec...   \n",
            "2     [he, has, a, major, in, philosophy, which, is,...   \n",
            "3     [i, thought, his, class, was, extremely, hard,...   \n",
            "4     [i, recently, just, finished, taking, comp, wi...   \n",
            "...                                                 ...   \n",
            "2340  [hes, really, disoriented, but, a, really, coo...   \n",
            "2341                                     [no, comments]   \n",
            "2342                                         [horrible]   \n",
            "2343                                     [no, comments]   \n",
            "2344                                     [no, comments]   \n",
            "\n",
            "                              comment_tokenized_cleaned  \\\n",
            "0     [rand, good, guy, really, felt, alterego, left...   \n",
            "1     [brilliant, field, expects, students, perform,...   \n",
            "2     [major, philosophy, papers, write, based, phil...   \n",
            "3     [thought, class, extremely, hard, despite, bec...   \n",
            "4     [recently, finished, taking, comp, rand, harde...   \n",
            "...                                                 ...   \n",
            "2340  [hes, really, disoriented, really, cool, guy, ...   \n",
            "2341                                         [comments]   \n",
            "2342                                         [horrible]   \n",
            "2343                                         [comments]   \n",
            "2344                                         [comments]   \n",
            "\n",
            "                              comment_tokenized_stemmed  \n",
            "0     [rand, good, guy, realli, felt, alterego, left...  \n",
            "1     [brilliant, field, expect, student, perform, h...  \n",
            "2     [major, philosophi, paper, write, base, philos...  \n",
            "3     [thought, class, extrem, hard, despit, becam, ...  \n",
            "4     [recent, finish, take, comp, rand, hardest, cl...  \n",
            "...                                                 ...  \n",
            "2340  [he, realli, disori, realli, cool, guy, funni,...  \n",
            "2341                                          [comment]  \n",
            "2342                                          [horribl]  \n",
            "2343                                          [comment]  \n",
            "2344                                          [comment]  \n",
            "\n",
            "[2345 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Inisialisasi Tokenizer dan fit pada data tokenized stemmed\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['comment_tokenized_stemmed'])\n",
        "\n",
        "# Mengubah token menjadi urutan angka\n",
        "df['comment_tokenized_padded'] = tokenizer.texts_to_sequences(df['comment_tokenized_stemmed'])\n",
        "\n",
        "# Padding untuk menyamakan panjang urutan\n",
        "max_len = 10  # Anda bisa mengubah panjang maksimal sesuai kebutuhan\n",
        "df['comment_tokenized_padded'] = pad_sequences(df['comment_tokenized_padded'], maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Menampilkan hasil setelah padding\n",
        "print(\"Data setelah Padding:\")\n",
        "print(df[['comment', 'comment_tokenized', 'comment_tokenized_stemmed', 'comment_tokenized_padded']])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZqJDXfnp2vx",
        "outputId": "8df875bb-71c0-49a5-f861-cb4ffee1eba5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data setelah Padding:\n",
            "                                                comment  \\\n",
            "0     Rand was a good guy, really... he was. But I f...   \n",
            "1     He is brilliant in his field, but expects his ...   \n",
            "2     He has a major in philosophy which is why all ...   \n",
            "3     I thought his class was extremely hard but des...   \n",
            "4     I recently just finished taking Comp 110 with ...   \n",
            "...                                                 ...   \n",
            "2340  He's really disoriented, but a really cool guy...   \n",
            "2341                                        No Comments   \n",
            "2342                                           Horrible   \n",
            "2343                                        No Comments   \n",
            "2344                                        No Comments   \n",
            "\n",
            "                                      comment_tokenized  \\\n",
            "0     [rand, was, a, good, guy, really, he, was, but...   \n",
            "1     [he, is, brilliant, in, his, field, but, expec...   \n",
            "2     [he, has, a, major, in, philosophy, which, is,...   \n",
            "3     [i, thought, his, class, was, extremely, hard,...   \n",
            "4     [i, recently, just, finished, taking, comp, wi...   \n",
            "...                                                 ...   \n",
            "2340  [hes, really, disoriented, but, a, really, coo...   \n",
            "2341                                     [no, comments]   \n",
            "2342                                         [horrible]   \n",
            "2343                                     [no, comments]   \n",
            "2344                                     [no, comments]   \n",
            "\n",
            "                              comment_tokenized_stemmed  \\\n",
            "0     [rand, good, guy, realli, felt, alterego, left...   \n",
            "1     [brilliant, field, expect, student, perform, h...   \n",
            "2     [major, philosophi, paper, write, base, philos...   \n",
            "3     [thought, class, extrem, hard, despit, becam, ...   \n",
            "4     [recent, finish, take, comp, rand, hardest, cl...   \n",
            "...                                                 ...   \n",
            "2340  [he, realli, disori, realli, cool, guy, funni,...   \n",
            "2341                                          [comment]   \n",
            "2342                                          [horribl]   \n",
            "2343                                          [comment]   \n",
            "2344                                          [comment]   \n",
            "\n",
            "      comment_tokenized_padded  \n",
            "0                          529  \n",
            "1                          414  \n",
            "2                          144  \n",
            "3                          219  \n",
            "4                         1036  \n",
            "...                        ...  \n",
            "2340                        26  \n",
            "2341                       100  \n",
            "2342                       134  \n",
            "2343                       100  \n",
            "2344                       100  \n",
            "\n",
            "[2345 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggabungkan token yang sudah melalui stopword removal dan stemming menjadi satu kalimat\n",
        "df['comment_cleaned_final'] = df['comment_tokenized_stemmed'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Menampilkan hasil akhir setelah digabungkan menjadi kalimat\n",
        "print(\"Data Setelah Semua Tahapan Preprocessing Menjadi Satu Kalimat:\")\n",
        "print(df[['comment', 'comment_cleaned_final']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC6rQD2bsZPb",
        "outputId": "dc5ab2ee-bc8e-4b47-d12e-1b6ee7154927"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Setelah Semua Tahapan Preprocessing Menjadi Satu Kalimat:\n",
            "                                             comment  \\\n",
            "0  Rand was a good guy, really... he was. But I f...   \n",
            "1  He is brilliant in his field, but expects his ...   \n",
            "2  He has a major in philosophy which is why all ...   \n",
            "3  I thought his class was extremely hard but des...   \n",
            "4  I recently just finished taking Comp 110 with ...   \n",
            "\n",
            "                               comment_cleaned_final  \n",
            "0  rand good guy realli felt alterego left go hom...  \n",
            "1  brilliant field expect student perform high le...  \n",
            "2  major philosophi paper write base philosophi l...  \n",
            "3  thought class extrem hard despit becam confid ...  \n",
            "4  recent finish take comp rand hardest class fre...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melihat nilai unik dan jumlah kemunculan kategori Good dan Bad\n",
        "quality_grouped_counts = df['quality_grouped'].value_counts()\n",
        "print(\"\\nJumlah Kategori Good dan Bad:\")\n",
        "print(quality_grouped_counts)\n",
        "\n",
        "# Mapping rating 'Good' menjadi 1 dan 'Bad' menjadi 0\n",
        "rating_to_numeric = {'Good': 1, 'Bad': 0}\n",
        "\n",
        "# Menambahkan kolom baru dengan rating yang telah dipetakan ke nilai numerik\n",
        "df['rating_numeric'] = df['quality_grouped'].map(rating_to_numeric)\n",
        "\n",
        "# Menampilkan hasil setelah mapping\n",
        "print(\"\\nData Setelah Mapping Rating ke Numerik:\")\n",
        "print(df[[ 'rating_numeric', 'comment_cleaned_final']].head())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CU0GuG0uF4z",
        "outputId": "354f6aca-5f95-4a98-d319-a591bb625246"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Jumlah Kategori Good dan Bad:\n",
            "quality_grouped\n",
            "Good    1459\n",
            "Bad      886\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Data Setelah Mapping Rating ke Numerik:\n",
            "   rating_numeric                              comment_cleaned_final\n",
            "0               0  rand good guy realli felt alterego left go hom...\n",
            "1               0  brilliant field expect student perform high le...\n",
            "2               0  major philosophi paper write base philosophi l...\n",
            "3               1  thought class extrem hard despit becam confid ...\n",
            "4               0  recent finish take comp rand hardest class fre...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import yang diperlukan\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Inisialisasi TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Membatasi jumlah fitur (kata)\n",
        "\n",
        "# Terapkan TF-IDF pada kolom 'comment_cleaned_final' (asumsi ini kolom setelah data cleaning)\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['comment_cleaned_final'])\n",
        "\n",
        "# Konversi hasil ke dalam bentuk array\n",
        "X_tfidf_array = X_tfidf.toarray()\n",
        "\n",
        "# Target variabel (Rating_num)\n",
        "y = df['rating_numeric'].values\n",
        "\n",
        "# Membagi data menjadi training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_array, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tampilkan beberapa baris data TF-IDF sebagai DataFrame\n",
        "X_tfidf_df = pd.DataFrame(X_tfidf_array, columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "# Menampilkan beberapa baris data TF-IDF\n",
        "print(X_tfidf_df.head())\n",
        "max_len = X_tfidf_array.shape[1]  # Panjang maksimal fitur yang dihasilkan TF-IDF\n",
        "X_train_padded = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test_padded = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-XRjhTR2G3P",
        "outputId": "45f16ac2-818e-4adf-df41-a6f93976214b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ab  abara  abarra  abens  abid  abil  abl  abnorm  abort  abouth  ...  \\\n",
            "0  0.0    0.0     0.0    0.0   0.0   0.0  0.0     0.0    0.0     0.0  ...   \n",
            "1  0.0    0.0     0.0    0.0   0.0   0.0  0.0     0.0    0.0     0.0  ...   \n",
            "2  0.0    0.0     0.0    0.0   0.0   0.0  0.0     0.0    0.0     0.0  ...   \n",
            "3  0.0    0.0     0.0    0.0   0.0   0.0  0.0     0.0    0.0     0.0  ...   \n",
            "4  0.0    0.0     0.0    0.0   0.0   0.0  0.0     0.0    0.0     0.0  ...   \n",
            "\n",
            "   youu  youv   yr   yu  zero  zone  zoo  zool  zoolog  zoologist  \n",
            "0   0.0   0.0  0.0  0.0   0.0   0.0  0.0   0.0     0.0        0.0  \n",
            "1   0.0   0.0  0.0  0.0   0.0   0.0  0.0   0.0     0.0        0.0  \n",
            "2   0.0   0.0  0.0  0.0   0.0   0.0  0.0   0.0     0.0        0.0  \n",
            "3   0.0   0.0  0.0  0.0   0.0   0.0  0.0   0.0     0.0        0.0  \n",
            "4   0.0   0.0  0.0  0.0   0.0   0.0  0.0   0.0     0.0        0.0  \n",
            "\n",
            "[5 rows x 3882 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODELING"
      ],
      "metadata": {
        "id": "SiM865PL44R1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import yang diperlukan\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Misalkan df sudah berisi data yang telah dibersihkan dan preprocessed\n",
        "# Terapkan TF-IDF pada kolom 'comment_cleaned_final' (asumsi ini kolom setelah data cleaning)\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Membatasi jumlah fitur (kata) menjadi 5000\n",
        "\n",
        "# Terapkan TF-IDF\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['comment_cleaned_final'])\n",
        "\n",
        "# Konversi hasil ke dalam bentuk array\n",
        "X_tfidf_array = X_tfidf.toarray()\n",
        "\n",
        "# Target variabel (Rating_num)\n",
        "y = df['rating_numeric'].values\n",
        "\n",
        "# Membagi data menjadi training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_array, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Menampilkan beberapa baris data TF-IDF sebagai DataFrame (optional)\n",
        "X_tfidf_df = pd.DataFrame(X_tfidf_array, columns=tfidf_vectorizer.get_feature_names_out())\n",
        "print(X_tfidf_df.head())\n",
        "\n",
        "# Tentukan panjang input berdasarkan hasil TF-IDF\n",
        "max_len = X_tfidf_array.shape[1]  # Panjang fitur dari hasil TF-IDF\n",
        "\n",
        "# Ubah input data agar sesuai dengan dimensi LSTM: (batch_size, timesteps, features)\n",
        "# Karena kita tidak memiliki urutan waktu, kita akan menambahkan dimensi waktu sebagai 1\n",
        "X_train_reshaped = np.expand_dims(X_train, axis=-1)\n",
        "X_test_reshaped = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "# 5. Membangun Model LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Menambahkan LSTM layer (Langsung menggunakan input TF-IDF yang sudah direshape)\n",
        "model.add(LSTM(128, input_shape=(max_len, 1), return_sequences=False))  # LSTM dengan 128 unit\n",
        "\n",
        "# Menambahkan Dropout untuk menghindari overfitting\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Menambahkan layer Dense untuk output\n",
        "model.add(Dense(1, activation='sigmoid'))  # Menggunakan sigmoid untuk klasifikasi biner (Good vs. Bad)\n",
        "\n",
        "# Menyusun model dengan optimizer dan loss function yang sesuai\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Menampilkan ringkasan model\n",
        "model.summary()\n",
        "\n",
        "# Melatih model\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=3, batch_size=64, validation_data=(X_test_reshaped, y_test))\n",
        "\n",
        "# Evaluasi model pada data uji\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "7YV8U6kX4svx",
        "outputId": "831d629e-ba4d-4588-af65-135ef13d12c1"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ab  abara  abarra  abens  abid  abil  abl  abnorm  abort  abouth  ...  \\\n",
            "0  0.0    0.0     0.0    0.0   0.0   0.0  0.0     0.0    0.0     0.0  ...   \n",
            "1  0.0    0.0     0.0    0.0   0.0   0.0  0.0     0.0    0.0     0.0  ...   \n",
            "2  0.0    0.0     0.0    0.0   0.0   0.0  0.0     0.0    0.0     0.0  ...   \n",
            "3  0.0    0.0     0.0    0.0   0.0   0.0  0.0     0.0    0.0     0.0  ...   \n",
            "4  0.0    0.0     0.0    0.0   0.0   0.0  0.0     0.0    0.0     0.0  ...   \n",
            "\n",
            "   youu  youv   yr   yu  zero  zone  zoo  zool  zoolog  zoologist  \n",
            "0   0.0   0.0  0.0  0.0   0.0   0.0  0.0   0.0     0.0        0.0  \n",
            "1   0.0   0.0  0.0  0.0   0.0   0.0  0.0   0.0     0.0        0.0  \n",
            "2   0.0   0.0  0.0  0.0   0.0   0.0  0.0   0.0     0.0        0.0  \n",
            "3   0.0   0.0  0.0  0.0   0.0   0.0  0.0   0.0     0.0        0.0  \n",
            "4   0.0   0.0  0.0  0.0   0.0   0.0  0.0   0.0     0.0        0.0  \n",
            "\n",
            "[5 rows x 3882 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m66,560\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m66,689\u001b[0m (260.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,689</span> (260.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m66,689\u001b[0m (260.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,689</span> (260.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 8s/step - accuracy: 0.5913 - loss: 0.6810 - val_accuracy: 0.6567 - val_loss: 0.6473\n",
            "Epoch 2/3\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 9s/step - accuracy: 0.6099 - loss: 0.6689 - val_accuracy: 0.6567 - val_loss: 0.6470\n",
            "Epoch 3/3\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 8s/step - accuracy: 0.6091 - loss: 0.6701 - val_accuracy: 0.6567 - val_loss: 0.6482\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - accuracy: 0.6704 - loss: 0.6422\n",
            "Test Accuracy: 0.6567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=3, batch_size=64, validation_data=(X_test_reshaped, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSQxGATbGmKD",
        "outputId": "9a5ce0d0-28c4-40b7-e365-536b4cea140e"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 9s/step - accuracy: 0.6152 - loss: 0.6675 - val_accuracy: 0.6567 - val_loss: 0.6468\n",
            "Epoch 2/3\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 8s/step - accuracy: 0.6057 - loss: 0.6728 - val_accuracy: 0.6567 - val_loss: 0.6465\n",
            "Epoch 3/3\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 8s/step - accuracy: 0.6087 - loss: 0.6707 - val_accuracy: 0.6567 - val_loss: 0.6469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi model pada data uji\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJqMy7ymJwQi",
        "outputId": "65e6b234-a585-40ad-f28a-167702ecf2a7"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.6704 - loss: 0.6404\n",
            "Test Accuracy: 0.6567\n"
          ]
        }
      ]
    }
  ]
}